# -*- coding: utf-8 -*-
"""Tesis1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aQ9Ybcab7y5eiN7aiEReVg1EMUvYwYkh

Configuración del entorno.
"""

!pip install transformers
!pip install datasets
!pip install torch
!pip install scikit-learn
!pip install accelerate -U
!pip install transformers[torch]
!pip install scipy
!pip install spacy
!pip install nltk
!python -m spacy download es_core_news_sm

"""Drive."""

from google.colab import drive
drive.mount('/content/drive')

"""Carga de dataset."""

import pandas as pd

# Ruta del archivo en Google Drive
file_path = '/content/drive/My Drive/DatasetTesis.xlsx'  # Ajusta esta ruta según la ubicación y nombre exacto de tu archivo

# Cargar el dataset desde el archivo subido
data = pd.read_excel(file_path, usecols=['tema', 'pregunta', 'texto_correcto', 'texto_incorrecto'])
print(data.head())

"""Division de los datos."""

from sklearn.model_selection import train_test_split

# Dividir los datos en conjuntos de entrenamiento y prueba
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

# Crear conjuntos de datos de entrenamiento y validación
train_data = train_data.reset_index(drop=True)
test_data = test_data.reset_index(drop=True)

"""Tokenización."""

from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')

def tokenize_data(data):
    return tokenizer(data['pregunta'].tolist(), padding=True, truncation=True, return_tensors="pt")

train_encodings = tokenize_data(train_data)
test_encodings = tokenize_data(test_data)

"""QA dataset"""

import torch
from torch.utils.data import Dataset

class QADataset(Dataset):
    def __init__(self, encodings, answers):
        self.encodings = encodings
        self.answers = answers

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.answers[idx])
        return item

    def __len__(self):
        return len(self.answers)

# Convertir respuestas correctas e incorrectas en etiquetas
def create_labels(data):
    labels = []
    for i in range(len(data)):
        correct_answer = data['texto_correcto'][i]
        incorrect_answer = data['texto_incorrecto'][i]
        labels.append(1 if correct_answer else 0)
    return labels

train_labels = create_labels(train_data)
test_labels = create_labels(test_data)

train_dataset = QADataset(train_encodings, train_labels)
test_dataset = QADataset(test_encodings, test_labels)

"""Definicion y entrenamiento del modelo."""

from transformers import BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from torch.utils.data import DataLoader, RandomSampler, SequentialSampler

# Definir el modelo
model = BertForSequenceClassification.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')
model.train()

# Definir el optimizador y el scheduler
optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)
total_steps = len(train_dataset) * 12  # Número de épocas
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)

# Crear dataloaders
train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=8)
test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=8)

# Configurar el dispositivo (GPU o CPU)
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Bucle de entrenamiento
for epoch in range(12):  # Número de épocas
    print(f"Epoch {epoch + 1}/{12}")
    for step, batch in enumerate(train_dataloader):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        print(f"Step {step + 1}/{len(train_dataloader)}, Loss: {loss.item()}")

        loss.backward()
        optimizer.step()
        scheduler.step()

print("Entrenamiento completo.")

"""Evaluacion del modelo."""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# Asegúrate de que el modelo esté en modo evaluación
model.eval()

# Variables para almacenar las predicciones y las etiquetas verdaderas
predictions = []
true_labels = []

# Iterar sobre el conjunto de datos de prueba
for batch in test_dataloader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)

    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)

    logits = outputs.logits
    preds = torch.argmax(logits, dim=-1)

    predictions.extend(preds.cpu().numpy())
    true_labels.extend(labels.cpu().numpy())

# Calcular las métricas de evaluación
accuracy = accuracy_score(true_labels, predictions)
precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')

print(f"Precisión: {accuracy:.4f}")
print(f"Precisión (Precision): {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")

"""Funcion de obetencion de embeddings y similitud porcoseno de los mismos."""

from sklearn.metrics.pairwise import cosine_similarity
from transformers import AutoTokenizer, AutoModel
import torch
import numpy as np

# Cargar el modelo y el tokenizador de BETO
beto_tokenizer = AutoTokenizer.from_pretrained("dccuchile/bert-base-spanish-wwm-uncased")
beto_model = AutoModel.from_pretrained("dccuchile/bert-base-spanish-wwm-uncased")

# Función para obtener embeddings de BETO
def get_embeddings(text):
    inputs = beto_tokenizer(text, return_tensors='pt', padding=True, truncation=True)
    with torch.no_grad():
        outputs = beto_model(**inputs)
    # Promediar los embeddings de todas las capas de salida
    embeddings = outputs.last_hidden_state.mean(dim=1)
    return embeddings

# Similitud con BETO
def compute_beto_similarity(text1, text2):
    embeddings1 = get_embeddings(text1)
    embeddings2 = get_embeddings(text2)
    similarity = cosine_similarity(embeddings1.numpy(), embeddings2.numpy())
    return similarity[0][0]

"""Funcion interactiva."""

from transformers import BertTokenizer, BertModel
import torch
from sklearn.metrics.pairwise import cosine_similarity

# Definir el tokenizador y el modelo BETO base
tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')
model = BertModel.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')

# Función para obtener embeddings de texto usando BETO
def get_beto_embeddings(text):
    inputs = tokenizer(text, padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
        embeddings = outputs.last_hidden_state[:, 0, :]  # Tomar el embedding correspondiente al token [CLS]
    return embeddings

# Función para calcular similitud coseno entre dos textos
def compute_similarity(text1, text2):
    embeddings1 = get_beto_embeddings(text1)
    embeddings2 = get_beto_embeddings(text2)

    # Calcular similitud coseno entre los embeddings
    sim = cosine_similarity(embeddings1.cpu().numpy(), embeddings2.cpu().numpy())[0][0]

    return sim

# Función para chequear y corregir la respuesta del usuario
def check_and_correct_answer_beto(question, user_answer, correct_answer):
    user_answer = user_answer.strip()
    correct_answer = correct_answer.strip()

    # Calcular similitud entre la respuesta del usuario y la respuesta correcta
    similarity = compute_similarity(user_answer, correct_answer)

    threshold = 0.7  # Umbral para considerar una respuesta como correcta

    if similarity >= threshold:
        return f"Correcta. La respuesta correcta es: {correct_answer}. La similitud es {similarity:.4f}"
    else:
        return f"Incorrecta. La respuesta correcta es: {correct_answer}. La similitud es {similarity:.4f}"

# Ejemplo de bucle interactivo
while True:
    try:
        print("Selecciona una categoría:")
        temas_unicos = data['tema'].unique()
        tema_dict = {idx + 1: tema for idx, tema in enumerate(temas_unicos)}

        for idx, tema in tema_dict.items():
            print(f"{idx}. {tema}")
        print(f"{len(tema_dict) + 1}. Salir")

        category = int(input("Elige una categoría (número): "))
        if category == len(tema_dict) + 1:
            break
        elif category not in tema_dict:
            print("Categoría no válida. Inténtalo de nuevo.")
            continue

        tema = tema_dict[category]

        preguntas_tema = data[data['tema'] == tema]['pregunta'].tolist()

        if not preguntas_tema:
            print(f"No hay preguntas disponibles para la categoría {tema}. Inténtalo de nuevo.")
            continue

        print(f"Selecciona una pregunta:")
        for idx, pregunta in enumerate(preguntas_tema):
            print(f"{idx + 1}. {pregunta}")

        pregunta_idx = int(input("Elige una pregunta (número): ")) - 1
        if pregunta_idx not in range(len(preguntas_tema)):
            print("Pregunta no válida. Inténtalo de nuevo.")
            continue

        selected_question = preguntas_tema[pregunta_idx]
        correct_answer = data[data['pregunta'] == selected_question]['texto_correcto'].values[0]

        user_answer = input(f"Pregunta: {selected_question}\nTu respuesta: ")

        result = check_and_correct_answer_beto(selected_question, user_answer, correct_answer)
        print(result)
        print()
    except Exception as e:
        print(f"Error: {e}")
        continue

"""Pruebas 1 sin preprocesamiento."""

import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import torch
from transformers import BertTokenizer, BertModel

# Definir el tokenizador y el modelo BETO base
tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')
model = BertModel.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')

# Función para obtener embeddings de texto usando BETO
def get_beto_embeddings(text):
    inputs = tokenizer(text, padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
        embeddings = outputs.last_hidden_state[:, 0, :]  # Tomar el embedding correspondiente al token [CLS]
    return embeddings

# Función para calcular similitud coseno entre dos textos
def compute_similarity(text1, text2):
    embeddings1 = get_beto_embeddings(text1)
    embeddings2 = get_beto_embeddings(text2)

    # Calcular similitud coseno entre los embeddings
    sim = cosine_similarity(embeddings1.cpu().numpy(), embeddings2.cpu().numpy())[0][0]

    return sim

# Leer el archivo desde Google Drive
file_path = '/content/drive/My Drive/DatasetTesis.xlsx'
data = pd.read_excel(file_path, usecols=['tema', 'pregunta', 'texto_correcto', 'texto_incorrecto'])

# Umbral para considerar una respuesta como correcta
threshold = 0.7

# Iterar sobre las preguntas y comparar las respuestas correctas e incorrectas
for index, row in data.iterrows():
    pregunta = row['pregunta']
    respuesta_correcta = row['texto_correcto']
    respuesta_incorrecta = row['texto_incorrecto']

    similarity = compute_similarity(respuesta_incorrecta, respuesta_correcta)

    eval_result = "Correcta" if similarity >= threshold else "Incorrecta"

    print(f"Pregunta: {pregunta}")
    print(f"Respuesta Correcta: {respuesta_correcta}")
    print(f"Respuesta Incorrecta: {respuesta_incorrecta}")
    print(f"Similitud entre Respuesta Incorrecta y Correcta: {similarity:.4f} - Evaluación: {eval_result}")
    print()

"""Prueba 2 con preprocesamiento."""

import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import torch
from transformers import BertTokenizer, BertModel
import spacy
from spacy.lang.es import Spanish

# Cargar modelo de spacy para español
nlp = Spanish()

# Definir funciones de lematización y eliminación de stopwords
def preprocess_text(text):
    # Tokenizar y lematizar (o stem si se prefiere) usando spacy
    doc = nlp(text.lower())
    lemmas = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]
    return " ".join(lemmas)

# Definir el tokenizador y el modelo BETO base
tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')
model = BertModel.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')

# Función para obtener embeddings de texto usando BETO con preprocesamiento
def get_beto_embeddings(text):
    preprocessed_text = preprocess_text(text)
    inputs = tokenizer(preprocessed_text, padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
        embeddings = outputs.last_hidden_state[:, 0, :]  # Tomar el embedding correspondiente al token [CLS]
    return embeddings

# Función para calcular similitud coseno entre dos textos con preprocesamiento
def compute_similarity(text1, text2):
    embeddings1 = get_beto_embeddings(text1)
    embeddings2 = get_beto_embeddings(text2)

    # Calcular similitud coseno entre los embeddings
    sim = cosine_similarity(embeddings1.cpu().numpy(), embeddings2.cpu().numpy())[0][0]

    return sim

# Leer el archivo desde Google Drive
file_path = '/content/drive/My Drive/DatasetTesis.xlsx'
data = pd.read_excel(file_path, usecols=['tema', 'pregunta', 'texto_correcto', 'texto_incorrecto'])

# Umbral para considerar una respuesta como correcta
threshold = 0.7

# Iterar sobre las preguntas y comparar las respuestas correctas e incorrectas con preprocesamiento
for index, row in data.iterrows():
    pregunta = row['pregunta']
    respuesta_correcta = preprocess_text(row['texto_correcto'])
    respuesta_incorrecta = preprocess_text(row['texto_incorrecto'])

    similarity_correct = compute_similarity(pregunta, respuesta_correcta)
    similarity_incorrect = compute_similarity(pregunta, respuesta_incorrecta)

    correct_eval = "Correcta" if similarity_correct >= threshold else "Incorrecta"
    incorrect_eval = "Correcta" if similarity_incorrect >= threshold else "Incorrecta"

    print(f"Pregunta: {pregunta}")
    print(f"Respuesta Correcta: {row['texto_correcto']}")
    print(f"Respuesta Incorrecta: {row['texto_incorrecto']}")
    print(f"Similitud entre Respuesta Correcta y Pregunta: {similarity_correct:.4f} - Evaluación: {correct_eval}")
    print(f"Similitud entre Respuesta Incorrecta y Pregunta: {similarity_incorrect:.4f} - Evaluación: {incorrect_eval}")
    print()